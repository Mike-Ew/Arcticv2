\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{zakhvatkina2019satellite}
\citation{dosovitskiy2020image}
\citation{aleissaee2023}
\citation{zhang2024cnn}
\citation{xia2025vision}
\citation{chen2023sea}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}{section.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Sentinel-1 SAR imagery showing the ambiguity of ice signatures. Texture and context are often more discriminative than pixel intensity alone.}}{1}{figure.1}\protected@file@percent }
\newlabel{fig:sar_vis}{{1}{1}{Sentinel-1 SAR imagery showing the ambiguity of ice signatures. Texture and context are often more discriminative than pixel intensity alone}{figure.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {II}Related Work}{1}{section.2}\protected@file@percent }
\citation{sun2019monitoring}
\citation{li2021fusion}
\citation{wiehle2024sea}
\citation{deloe2025fusing}
\citation{andersson2025deep,li2024advancing}
\citation{asip2024}
\citation{chen2024comparative}
\citation{chen2024colocated}
\citation{khan2024transformer}
\citation{xia2025vision}
\citation{khan2024transformer}
\citation{khan2024transformer}
\citation{saldo2021ai4arctic}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {II-A}}Emerging Trends: Multimodal Fusion and Weakly Supervised Learning}{2}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {III}Methodology}{2}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-A}}Proposed Multimodal Framework}{2}{subsection.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces The proposed Multimodal Temporal-Spatial Vision Transformer (TSViT) architecture. A Cross-Modal Attention Fusion module integrates features from SAR, Optical, and Meteorological streams, while an Explainability module outputs Attribution Maps.}}{2}{figure.2}\protected@file@percent }
\newlabel{fig:arch}{{2}{2}{The proposed Multimodal Temporal-Spatial Vision Transformer (TSViT) architecture. A Cross-Modal Attention Fusion module integrates features from SAR, Optical, and Meteorological streams, while an Explainability module outputs Attribution Maps}{figure.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-B}}Explainability via Integrated Gradients}{2}{subsection.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-C}}Data-Centric Pipeline}{2}{subsection.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {III-C}1}Full-Resolution Input}{2}{subsubsection.3.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {III-C}2}Correcting Data Leakage}{2}{subsubsection.3.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {III-C}3}High-Fidelity Labeling}{2}{subsubsection.3.3.3}\protected@file@percent }
\citation{lin2020focal}
\citation{li2020deep}
\bibstyle{IEEEtran}
\bibdata{references}
\bibcite{zakhvatkina2019satellite}{1}
\bibcite{dosovitskiy2020image}{2}
\bibcite{aleissaee2023}{3}
\bibcite{zhang2024cnn}{4}
\bibcite{xia2025vision}{5}
\bibcite{chen2023sea}{6}
\bibcite{sun2019monitoring}{7}
\bibcite{li2021fusion}{8}
\bibcite{wiehle2024sea}{9}
\bibcite{deloe2025fusing}{10}
\bibcite{andersson2025deep}{11}
\bibcite{li2024advancing}{12}
\bibcite{asip2024}{13}
\bibcite{chen2024comparative}{14}
\bibcite{chen2024colocated}{15}
\bibcite{khan2024transformer}{16}
\bibcite{saldo2021ai4arctic}{17}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\mbox  {III-C}4}Dynamic Normalization}{3}{subsubsection.3.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {IV}Experiments and Results}{3}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {IV-A}}Experimental Setup}{3}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {IV-B}}Results}{3}{subsection.4.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {I}{\ignorespaces Baseline SAR Model Performance}}{3}{table.1}\protected@file@percent }
\newlabel{tab:results}{{I}{3}{Baseline SAR Model Performance}{table.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {IV-C}}Discussion}{3}{subsection.4.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Confusion Matrix for the Champion ViT-Large Model.}}{3}{figure.3}\protected@file@percent }
\newlabel{fig:cm}{{3}{3}{Confusion Matrix for the Champion ViT-Large Model}{figure.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {V}Conclusion}{3}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{References}{3}{section*.1}\protected@file@percent }
\bibcite{lin2020focal}{18}
\bibcite{li2020deep}{19}
\gdef \@abspage@last{4}
