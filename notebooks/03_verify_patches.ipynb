{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Verify Preprocessed Scenes\n",
    "\n",
    "Sanity check that scene conversion is correct and random cropping works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom pathlib import Path, PureWindowsPath, PurePosixPath\nimport random\nimport json\nimport torch\nimport platform\n\n# Detect environment and set path accordingly\nif platform.system() == 'Windows':\n    # Running from Windows Python accessing WSL files\n    SCENE_DIR = Path(r'\\\\wsl.localhost\\Ubuntu-24.04\\home\\mike1\\Arcticv2\\data\\ai4arctic_hugging face\\npy_memmap')\nelse:\n    # Running from WSL/Linux\n    SCENE_DIR = Path('../data/ai4arctic_hugging face/npy_memmap')\n    if not SCENE_DIR.exists():\n        SCENE_DIR = Path('/home/mike1/Arcticv2/data/ai4arctic_hugging face/npy_memmap')\n\nprint(f\"Platform: {platform.system()}\")\nprint(f\"Scene directory: {SCENE_DIR}\")\nprint(f\"Directory exists: {SCENE_DIR.exists()}\")\n\n# Class names\nCLASS_NAMES = [\n    'OpenWater',\n    'NewIce',\n    'YoungIce',\n    'FirstYearIce',\n    'MultiYearIce',\n    'GlacialIce',\n]\n\n# Colors for each class\nCOLORS = [\n    [0, 0, 139],      # OpenWater - dark blue\n    [173, 216, 230],  # NewIce - light blue\n    [144, 238, 144],  # YoungIce - light green\n    [255, 255, 0],    # FirstYearIce - yellow\n    [255, 165, 0],    # MultiYearIce - orange\n    [255, 255, 255],  # GlacialIce - white\n]\nCOLORS = np.array(COLORS) / 255.0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": "# Check preprocessing output (memmap format: separate _image.npy and _label.npy files)\ntrain_images = list((SCENE_DIR / 'train').glob('*_image.npy'))\nval_images = list((SCENE_DIR / 'val').glob('*_image.npy'))\n\nprint(f'Train scenes: {len(train_images)}')\nprint(f'Val scenes: {len(val_images)}')\n\n# Load metadata\nif (SCENE_DIR / 'metadata.json').exists():\n    with open(SCENE_DIR / 'metadata.json') as f:\n        metadata = json.load(f)\n    print(f\"\\nMetadata:\")\n    print(f\"  Version: {metadata.get('version', 'N/A')}\")\n    print(f\"  Classes: {metadata.get('num_classes', 'N/A')}\")\n    print(f\"  Train scenes: {metadata.get('num_train_scenes', 'N/A')}\")\n    print(f\"  Val scenes: {metadata.get('num_val_scenes', 'N/A')}\")\n\n# Load normalization stats\nif (SCENE_DIR / 'normalization_stats.json').exists():\n    with open(SCENE_DIR / 'normalization_stats.json') as f:\n        stats = json.load(f)\n    print(f\"\\nNormalization stats:\")\n    for i, name in enumerate(stats['channel_names']):\n        print(f\"  {name}: mean={stats['mean'][i]:.4f}, std={stats['std'][i]:.4f}\")\n\n# Load coordinate counts\nif (SCENE_DIR / 'train_coords.npy').exists():\n    train_coords = np.load(SCENE_DIR / 'train_coords.npy', allow_pickle=True).item()\n    print(f\"\\nTrain coords: {len(train_coords['coords'])} crops\")\nif (SCENE_DIR / 'val_coords.npy').exists():\n    val_coords = np.load(SCENE_DIR / 'val_coords.npy', allow_pickle=True).item()\n    print(f\"Val coords: {len(val_coords['coords'])} crops\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": "def load_scene(image_path):\n    \"\"\"Load a scene from memmap format (separate _image.npy and _label.npy files).\"\"\"\n    label_path = str(image_path).replace('_image.npy', '_label.npy')\n    image = np.load(image_path, mmap_mode='r')  # [3, H, W] float16\n    label = np.load(label_path, mmap_mode='r')  # [H, W] uint8\n    return image, label\n\ndef label_to_rgb(label):\n    \"\"\"Convert label to RGB image for visualization.\"\"\"\n    H, W = label.shape\n    rgb = np.zeros((H, W, 3))\n    \n    for cls_idx, color in enumerate(COLORS):\n        mask = label == cls_idx\n        rgb[mask] = color\n    \n    # Mark ignore pixels (255) as gray\n    ignore_mask = label == 255\n    rgb[ignore_mask] = [0.5, 0.5, 0.5]\n    \n    return rgb\n\ndef visualize_scene(image_path, crop_size=256):\n    \"\"\"Visualize a full scene with a random crop highlighted.\"\"\"\n    image, label = load_scene(image_path)\n    H, W = label.shape\n    \n    # Pick a random crop location\n    r = random.randint(0, max(0, H - crop_size))\n    c = random.randint(0, max(0, W - crop_size))\n    \n    fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n    \n    # Top row: Full scene\n    axes[0, 0].imshow(image[0], cmap='gray', vmin=np.nanpercentile(image[0], 1), vmax=np.nanpercentile(image[0], 99))\n    axes[0, 0].set_title(f'Full Scene HH [{image.shape[1]}x{image.shape[2]}]')\n    axes[0, 0].add_patch(plt.Rectangle((c, r), crop_size, crop_size, fill=False, edgecolor='red', linewidth=2))\n    \n    axes[0, 1].imshow(image[1], cmap='gray', vmin=np.nanpercentile(image[1], 1), vmax=np.nanpercentile(image[1], 99))\n    axes[0, 1].set_title('Full Scene HV')\n    axes[0, 1].add_patch(plt.Rectangle((c, r), crop_size, crop_size, fill=False, edgecolor='red', linewidth=2))\n    \n    axes[0, 2].imshow(image[2], cmap='viridis')\n    axes[0, 2].set_title('Full Scene Incidence Angle')\n    axes[0, 2].add_patch(plt.Rectangle((c, r), crop_size, crop_size, fill=False, edgecolor='red', linewidth=2))\n    \n    label_rgb = label_to_rgb(label)\n    axes[0, 3].imshow(label_rgb)\n    axes[0, 3].set_title('Full Scene SOD Label')\n    axes[0, 3].add_patch(plt.Rectangle((c, r), crop_size, crop_size, fill=False, edgecolor='red', linewidth=2))\n    \n    # Bottom row: Crop (what training sees)\n    crop_img = image[:, r:r+crop_size, c:c+crop_size]\n    crop_lbl = label[r:r+crop_size, c:c+crop_size]\n    \n    axes[1, 0].imshow(crop_img[0], cmap='gray')\n    axes[1, 0].set_title(f'Crop HH [{crop_size}x{crop_size}]')\n    \n    axes[1, 1].imshow(crop_img[1], cmap='gray')\n    axes[1, 1].set_title('Crop HV')\n    \n    axes[1, 2].imshow(crop_img[2], cmap='viridis')\n    axes[1, 2].set_title('Crop Incidence Angle')\n    \n    crop_rgb = label_to_rgb(crop_lbl)\n    axes[1, 3].imshow(crop_rgb)\n    axes[1, 3].set_title(f'Crop Label (unique: {np.unique(crop_lbl).tolist()})')\n    \n    for ax in axes.flat:\n        ax.axis('off')\n    \n    plt.suptitle(image_path.name.replace('_image.npy', ''), fontsize=12)\n    plt.tight_layout()\n    plt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": "# Visualize 3 random train scenes\nprint('=== TRAIN SCENES ===')\nfor scene_path in random.sample(train_images, min(3, len(train_images))):\n    visualize_scene(scene_path)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": "# Visualize 2 random val scenes\nprint('=== VAL SCENES ===')\nfor scene_path in random.sample(val_images, min(2, len(val_images))):\n    visualize_scene(scene_path)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": "# Check scene sizes and class distribution\nprint('\\n=== SCENE STATISTICS ===')\n\nheights, widths = [], []\nclass_pixels = {i: 0 for i in range(6)}\nignore_pixels = 0\ntotal_pixels = 0\n\n# Sample scenes for distribution\nsample_scenes = random.sample(train_images, min(50, len(train_images)))\n\nfor path in sample_scenes:\n    _, label = load_scene(path)\n    heights.append(label.shape[0])\n    widths.append(label.shape[1])\n    \n    for cls_idx in range(6):\n        class_pixels[cls_idx] += (label == cls_idx).sum()\n    ignore_pixels += (label == 255).sum()\n    total_pixels += label.size\n\nprint(f'\\nScene dimensions (from {len(sample_scenes)} scenes):')\nprint(f'  Height: min={min(heights)}, max={max(heights)}, mean={np.mean(heights):.0f}')\nprint(f'  Width:  min={min(widths)}, max={max(widths)}, mean={np.mean(widths):.0f}')\n\nprint(f'\\nPixel distribution:')\nfor cls_idx, count in class_pixels.items():\n    pct = count / total_pixels * 100\n    print(f'  {CLASS_NAMES[cls_idx]}: {pct:.2f}%')\nprint(f'  Ignore (255): {ignore_pixels / total_pixels * 100:.2f}%')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Legend\n",
    "fig, ax = plt.subplots(figsize=(10, 1))\n",
    "for i, (name, color) in enumerate(zip(CLASS_NAMES, COLORS)):\n",
    "    ax.add_patch(plt.Rectangle((i, 0), 1, 1, color=color, edgecolor='black'))\n",
    "    ax.text(i + 0.5, 0.5, name, ha='center', va='center', fontsize=9,\n",
    "            color='black' if i != 5 else 'gray')  # GlacialIce is white, use gray text\n",
    "ax.add_patch(plt.Rectangle((6, 0), 1, 1, color=[0.5, 0.5, 0.5], edgecolor='black'))\n",
    "ax.text(6.5, 0.5, 'Ignore', ha='center', va='center', fontsize=9)\n",
    "ax.set_xlim(0, 7)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.axis('off')\n",
    "ax.set_title('Class Legend')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": "# Test the dataloader\nimport sys\nimport platform\n\nif platform.system() == 'Windows':\n    sys.path.insert(0, r'\\\\wsl.localhost\\Ubuntu-24.04\\home\\mike1\\Arcticv2\\src')\n    DATA_DIR = r'\\\\wsl.localhost\\Ubuntu-24.04\\home\\mike1\\Arcticv2\\data\\ai4arctic_hugging face'\nelse:\n    sys.path.insert(0, '../src')\n    DATA_DIR = '../data/ai4arctic_hugging face'\n\nfrom dataset import get_dataloaders\n\ntrain_loader, val_loader = get_dataloaders(\n    data_dir=DATA_DIR,\n    batch_size=4,\n    num_workers=0,\n    crop_size=256,\n    seed=42,\n)\n\nprint(f'Train batches: {len(train_loader)}')\nprint(f'Val batches: {len(val_loader)}')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": "# Visualize a batch from dataloader\nbatch = next(iter(train_loader))\nimages = batch['image']  # [B, 3, 256, 256]\nlabels = batch['label']  # [B, 256, 256]\n\nprint(f'Batch image shape: {images.shape}')\nprint(f'Batch label shape: {labels.shape}')\nprint(f'Image range: [{images.min():.2f}, {images.max():.2f}]')\nprint(f'Label unique values: {torch.unique(labels).tolist()}')\n\nfig, axes = plt.subplots(4, 4, figsize=(16, 16))\nfor i in range(4):\n    # HH\n    axes[i, 0].imshow(images[i, 0].numpy(), cmap='gray')\n    axes[i, 0].set_title(f'Sample {i} - HH')\n    axes[i, 0].axis('off')\n    \n    # HV\n    axes[i, 1].imshow(images[i, 1].numpy(), cmap='gray')\n    axes[i, 1].set_title(f'Sample {i} - HV')\n    axes[i, 1].axis('off')\n    \n    # Incidence\n    axes[i, 2].imshow(images[i, 2].numpy(), cmap='viridis')\n    axes[i, 2].set_title(f'Sample {i} - Incidence')\n    axes[i, 2].axis('off')\n    \n    # Label (convert -100 back to 255 for visualization)\n    lbl = labels[i].numpy().copy()\n    lbl[lbl == -100] = 255\n    axes[i, 3].imshow(label_to_rgb(lbl.astype(np.uint8)))\n    axes[i, 3].set_title(f'Sample {i} - Label')\n    axes[i, 3].axis('off')\n\nplt.suptitle('Batch from DataLoader (normalized, augmented)', fontsize=14)\nplt.tight_layout()\nplt.show()"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}