{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Verify Preprocessed Scenes\n",
    "\n",
    "Sanity check that scene conversion is correct and random cropping works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import random\n",
    "import json\n",
    "\n",
    "# Path to preprocessed scenes\n",
    "SCENE_DIR = Path('../data/ai4arctic_hugging face/npy_scenes')\n",
    "\n",
    "# Class names\n",
    "CLASS_NAMES = [\n",
    "    'OpenWater',\n",
    "    'NewIce',\n",
    "    'YoungIce',\n",
    "    'FirstYearIce',\n",
    "    'MultiYearIce',\n",
    "    'GlacialIce',\n",
    "]\n",
    "\n",
    "# Colors for each class\n",
    "COLORS = [\n",
    "    [0, 0, 139],      # OpenWater - dark blue\n",
    "    [173, 216, 230],  # NewIce - light blue\n",
    "    [144, 238, 144],  # YoungIce - light green\n",
    "    [255, 255, 0],    # FirstYearIce - yellow\n",
    "    [255, 165, 0],    # MultiYearIce - orange\n",
    "    [255, 255, 255],  # GlacialIce - white\n",
    "]\n",
    "COLORS = np.array(COLORS) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check preprocessing output\n",
    "train_scenes = list((SCENE_DIR / 'train').glob('*.npz'))\n",
    "val_scenes = list((SCENE_DIR / 'val').glob('*.npz'))\n",
    "\n",
    "print(f'Train scenes: {len(train_scenes)}')\n",
    "print(f'Val scenes: {len(val_scenes)}')\n",
    "\n",
    "# Load metadata\n",
    "if (SCENE_DIR / 'metadata.json').exists():\n",
    "    with open(SCENE_DIR / 'metadata.json') as f:\n",
    "        metadata = json.load(f)\n",
    "    print(f\"\\nMetadata:\")\n",
    "    print(f\"  Version: {metadata['version']}\")\n",
    "    print(f\"  Classes: {metadata['num_classes']}\")\n",
    "\n",
    "# Load normalization stats\n",
    "if (SCENE_DIR / 'normalization_stats.json').exists():\n",
    "    with open(SCENE_DIR / 'normalization_stats.json') as f:\n",
    "        stats = json.load(f)\n",
    "    print(f\"\\nNormalization stats:\")\n",
    "    for i, name in enumerate(stats['channel_names']):\n",
    "        print(f\"  {name}: mean={stats['mean'][i]:.4f}, std={stats['std'][i]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_scene(path):\n",
    "    \"\"\"Load a scene and return image, label.\"\"\"\n",
    "    data = np.load(path)\n",
    "    image = data['image']  # [3, H, W]\n",
    "    label = data['label']  # [H, W]\n",
    "    return image, label\n",
    "\n",
    "def label_to_rgb(label):\n",
    "    \"\"\"Convert label to RGB image for visualization.\"\"\"\n",
    "    H, W = label.shape\n",
    "    rgb = np.zeros((H, W, 3))\n",
    "    \n",
    "    for cls_idx, color in enumerate(COLORS):\n",
    "        mask = label == cls_idx\n",
    "        rgb[mask] = color\n",
    "    \n",
    "    # Mark ignore pixels (255) as gray\n",
    "    ignore_mask = label == 255\n",
    "    rgb[ignore_mask] = [0.5, 0.5, 0.5]\n",
    "    \n",
    "    return rgb\n",
    "\n",
    "def visualize_scene(path, crop_size=256):\n",
    "    \"\"\"Visualize a full scene with a random crop highlighted.\"\"\"\n",
    "    image, label = load_scene(path)\n",
    "    H, W = label.shape\n",
    "    \n",
    "    # Pick a random crop location\n",
    "    r = random.randint(0, max(0, H - crop_size))\n",
    "    c = random.randint(0, max(0, W - crop_size))\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
    "    \n",
    "    # Top row: Full scene\n",
    "    axes[0, 0].imshow(image[0], cmap='gray', vmin=np.nanpercentile(image[0], 1), vmax=np.nanpercentile(image[0], 99))\n",
    "    axes[0, 0].set_title(f'Full Scene HH [{image.shape[1]}x{image.shape[2]}]')\n",
    "    axes[0, 0].add_patch(plt.Rectangle((c, r), crop_size, crop_size, fill=False, edgecolor='red', linewidth=2))\n",
    "    \n",
    "    axes[0, 1].imshow(image[1], cmap='gray', vmin=np.nanpercentile(image[1], 1), vmax=np.nanpercentile(image[1], 99))\n",
    "    axes[0, 1].set_title('Full Scene HV')\n",
    "    axes[0, 1].add_patch(plt.Rectangle((c, r), crop_size, crop_size, fill=False, edgecolor='red', linewidth=2))\n",
    "    \n",
    "    axes[0, 2].imshow(image[2], cmap='viridis')\n",
    "    axes[0, 2].set_title('Full Scene Incidence Angle')\n",
    "    axes[0, 2].add_patch(plt.Rectangle((c, r), crop_size, crop_size, fill=False, edgecolor='red', linewidth=2))\n",
    "    \n",
    "    label_rgb = label_to_rgb(label)\n",
    "    axes[0, 3].imshow(label_rgb)\n",
    "    axes[0, 3].set_title('Full Scene SOD Label')\n",
    "    axes[0, 3].add_patch(plt.Rectangle((c, r), crop_size, crop_size, fill=False, edgecolor='red', linewidth=2))\n",
    "    \n",
    "    # Bottom row: Crop (what training sees)\n",
    "    crop_img = image[:, r:r+crop_size, c:c+crop_size]\n",
    "    crop_lbl = label[r:r+crop_size, c:c+crop_size]\n",
    "    \n",
    "    axes[1, 0].imshow(crop_img[0], cmap='gray')\n",
    "    axes[1, 0].set_title(f'Crop HH [{crop_size}x{crop_size}]')\n",
    "    \n",
    "    axes[1, 1].imshow(crop_img[1], cmap='gray')\n",
    "    axes[1, 1].set_title('Crop HV')\n",
    "    \n",
    "    axes[1, 2].imshow(crop_img[2], cmap='viridis')\n",
    "    axes[1, 2].set_title('Crop Incidence Angle')\n",
    "    \n",
    "    crop_rgb = label_to_rgb(crop_lbl)\n",
    "    axes[1, 3].imshow(crop_rgb)\n",
    "    axes[1, 3].set_title(f'Crop Label (unique: {np.unique(crop_lbl).tolist()})')\n",
    "    \n",
    "    for ax in axes.flat:\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.suptitle(path.name, fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize 3 random train scenes\n",
    "print('=== TRAIN SCENES ===')\n",
    "for scene_path in random.sample(train_scenes, min(3, len(train_scenes))):\n",
    "    visualize_scene(scene_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize 2 random val scenes\n",
    "print('=== VAL SCENES ===')\n",
    "for scene_path in random.sample(val_scenes, min(2, len(val_scenes))):\n",
    "    visualize_scene(scene_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check scene sizes and class distribution\n",
    "print('\\n=== SCENE STATISTICS ===')\n",
    "\n",
    "heights, widths = [], []\n",
    "class_pixels = {i: 0 for i in range(6)}\n",
    "ignore_pixels = 0\n",
    "total_pixels = 0\n",
    "\n",
    "# Sample scenes for distribution\n",
    "sample_scenes = random.sample(train_scenes, min(50, len(train_scenes)))\n",
    "\n",
    "for path in sample_scenes:\n",
    "    _, label = load_scene(path)\n",
    "    heights.append(label.shape[0])\n",
    "    widths.append(label.shape[1])\n",
    "    \n",
    "    for cls_idx in range(6):\n",
    "        class_pixels[cls_idx] += (label == cls_idx).sum()\n",
    "    ignore_pixels += (label == 255).sum()\n",
    "    total_pixels += label.size\n",
    "\n",
    "print(f'\\nScene dimensions (from {len(sample_scenes)} scenes):')\n",
    "print(f'  Height: min={min(heights)}, max={max(heights)}, mean={np.mean(heights):.0f}')\n",
    "print(f'  Width:  min={min(widths)}, max={max(widths)}, mean={np.mean(widths):.0f}')\n",
    "\n",
    "print(f'\\nPixel distribution:')\n",
    "for cls_idx, count in class_pixels.items():\n",
    "    pct = count / total_pixels * 100\n",
    "    print(f'  {CLASS_NAMES[cls_idx]}: {pct:.2f}%')\n",
    "print(f'  Ignore (255): {ignore_pixels / total_pixels * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Legend\n",
    "fig, ax = plt.subplots(figsize=(10, 1))\n",
    "for i, (name, color) in enumerate(zip(CLASS_NAMES, COLORS)):\n",
    "    ax.add_patch(plt.Rectangle((i, 0), 1, 1, color=color, edgecolor='black'))\n",
    "    ax.text(i + 0.5, 0.5, name, ha='center', va='center', fontsize=9,\n",
    "            color='black' if i != 5 else 'gray')  # GlacialIce is white, use gray text\n",
    "ax.add_patch(plt.Rectangle((6, 0), 1, 1, color=[0.5, 0.5, 0.5], edgecolor='black'))\n",
    "ax.text(6.5, 0.5, 'Ignore', ha='center', va='center', fontsize=9)\n",
    "ax.set_xlim(0, 7)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.axis('off')\n",
    "ax.set_title('Class Legend')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the dataloader\n",
    "import sys\n",
    "sys.path.insert(0, '../src')\n",
    "from dataset import get_dataloaders\n",
    "\n",
    "train_loader, val_loader = get_dataloaders(\n",
    "    data_dir='../data/ai4arctic_hugging face',\n",
    "    batch_size=4,\n",
    "    num_workers=0,\n",
    "    crop_size=256,\n",
    ")\n",
    "\n",
    "print(f'Train batches: {len(train_loader)}')\n",
    "print(f'Val batches: {len(val_loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a batch from dataloader\n",
    "batch = next(iter(train_loader))\n",
    "images = batch['image']  # [B, 3, 256, 256]\n",
    "labels = batch['label']  # [B, 256, 256]\n",
    "\n",
    "print(f'Batch image shape: {images.shape}')\n",
    "print(f'Batch label shape: {labels.shape}')\n",
    "print(f'Image range: [{images.min():.2f}, {images.max():.2f}]')\n",
    "print(f'Label unique values: {torch.unique(labels).tolist()}')\n",
    "\n",
    "fig, axes = plt.subplots(4, 4, figsize=(16, 16))\n",
    "for i in range(4):\n",
    "    # HH\n",
    "    axes[i, 0].imshow(images[i, 0].numpy(), cmap='gray')\n",
    "    axes[i, 0].set_title(f'Sample {i} - HH')\n",
    "    axes[i, 0].axis('off')\n",
    "    \n",
    "    # HV\n",
    "    axes[i, 1].imshow(images[i, 1].numpy(), cmap='gray')\n",
    "    axes[i, 1].set_title(f'Sample {i} - HV')\n",
    "    axes[i, 1].axis('off')\n",
    "    \n",
    "    # Incidence\n",
    "    axes[i, 2].imshow(images[i, 2].numpy(), cmap='viridis')\n",
    "    axes[i, 2].set_title(f'Sample {i} - Incidence')\n",
    "    axes[i, 2].axis('off')\n",
    "    \n",
    "    # Label (convert -100 back to 255 for visualization)\n",
    "    lbl = labels[i].numpy().copy()\n",
    "    lbl[lbl == -100] = 255\n",
    "    axes[i, 3].imshow(label_to_rgb(lbl.astype(np.uint8)))\n",
    "    axes[i, 3].set_title(f'Sample {i} - Label')\n",
    "    axes[i, 3].axis('off')\n",
    "\n",
    "plt.suptitle('Batch from DataLoader (normalized, augmented)', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
